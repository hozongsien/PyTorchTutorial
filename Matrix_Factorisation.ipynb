{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matrix Factorisation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZ1JukQnJr4l218zjMiqke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hozongsien/PyTorchTutorial/blob/master/Matrix_Factorisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WumaBX_EjoA",
        "colab_type": "text"
      },
      "source": [
        "# Matrix Factorisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zypll11hQbbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import rand as sprand\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIPu4wprQfcp",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok6CZZ4OQe1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RANDOM_SEED = 0\n",
        "NUM_EPOCHS = 3\n",
        "LEARNING_RATE = 1e-6\n",
        "BATCH_SIZE = 1\n",
        "PRINT_INTERVAL = 1000\n",
        "K = 20\n",
        "\n",
        "\n",
        "def set_seed(seed=RANDOM_SEED):\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    np.random.seed(seed=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj-NcsrkQGvu",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtxcvnoxEoJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set_seed()\n",
        "\n",
        "n_e1_features = 1000\n",
        "n_e2_features = 1000\n",
        "\n",
        "X = sprand(n_e1_features, n_e2_features, density=0.01, format='csr')\n",
        "X.data = (np.random.randint(0, 2, size=X.nnz).astype(np.float64))\n",
        "\n",
        "X = X.toarray() # convert from scipy to np array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT1q9JiVl86_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MatrixDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, X):\n",
        "        self.samples = []\n",
        "        self._init_dataset()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ((row, col), label) = self.samples[idx]\n",
        "\n",
        "        row = row.astype('long')\n",
        "        col = col.astype('long')\n",
        "        label = label.astype('float32')\n",
        "\n",
        "        sample = ((row, col), label)\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def _init_dataset(self):\n",
        "        for row, col in zip(*X.nonzero()):\n",
        "            input = (row, col)\n",
        "            label = X[row, col]\n",
        "            self.samples.append((input, label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsiUARIK27hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MatrixDataset(X)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id4T60WkQJIt",
        "colab_type": "text"
      },
      "source": [
        "## MF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCfrasDqFRBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MatrixFactorization(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, n_e1_features, n_e2_features, n_factors=20):\n",
        "        super().__init__()\n",
        "        self.U1 = torch.nn.Embedding(n_e1_features, n_factors, sparse=True)\n",
        "        self.U2 = torch.nn.Embedding(n_e2_features, n_factors, sparse=True)\n",
        "        \n",
        "\n",
        "    def forward(self, row, col):\n",
        "        # specific row/col of latent representation of U1/U2\n",
        "        return (self.U1(row) * self.U2(col)).sum(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhi7wj-pFfZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "net = MatrixFactorization(n_e1_features, n_e2_features, K).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zrhOumlQMes",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFSRDK-EuxRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e69abd0-52b9-4b55-b8f3-1621c5bb7aff"
      },
      "source": [
        "losses = []\n",
        "running_loss = 0.0\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for i, ((row, col), label) in enumerate(dataloader):\n",
        "        row = row.to(device)\n",
        "        col = col.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        prediction = net(row, col)\n",
        "        loss = criterion(prediction, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % (PRINT_INTERVAL) == (PRINT_INTERVAL - 1):\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / i + 1))\n",
        "            \n",
        "    running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 18.256\n",
            "[1,   200] loss: 18.914\n",
            "[1,   300] loss: 18.923\n",
            "[1,   400] loss: 20.244\n",
            "[1,   500] loss: 20.762\n",
            "[1,   600] loss: 21.673\n",
            "[1,   700] loss: 22.108\n",
            "[1,   800] loss: 22.388\n",
            "[1,   900] loss: 21.712\n",
            "[1,  1000] loss: 21.882\n",
            "[1,  1100] loss: 22.285\n",
            "[1,  1200] loss: 21.982\n",
            "[1,  1300] loss: 22.153\n",
            "[1,  1400] loss: 21.967\n",
            "[1,  1500] loss: 22.300\n",
            "[1,  1600] loss: 22.181\n",
            "[1,  1700] loss: 22.404\n",
            "[1,  1800] loss: 22.268\n",
            "[1,  1900] loss: 22.551\n",
            "[1,  2000] loss: 22.478\n",
            "[1,  2100] loss: 22.333\n",
            "[1,  2200] loss: 22.193\n",
            "[1,  2300] loss: 22.090\n",
            "[1,  2400] loss: 22.134\n",
            "[1,  2500] loss: 22.087\n",
            "[1,  2600] loss: 21.914\n",
            "[1,  2700] loss: 21.820\n",
            "[1,  2800] loss: 21.832\n",
            "[1,  2900] loss: 21.898\n",
            "[1,  3000] loss: 22.116\n",
            "[1,  3100] loss: 22.045\n",
            "[1,  3200] loss: 22.219\n",
            "[1,  3300] loss: 22.269\n",
            "[1,  3400] loss: 22.381\n",
            "[1,  3500] loss: 22.342\n",
            "[1,  3600] loss: 22.480\n",
            "[1,  3700] loss: 22.456\n",
            "[1,  3800] loss: 22.544\n",
            "[1,  3900] loss: 22.534\n",
            "[1,  4000] loss: 22.490\n",
            "[1,  4100] loss: 22.329\n",
            "[1,  4200] loss: 22.337\n",
            "[1,  4300] loss: 22.302\n",
            "[1,  4400] loss: 22.346\n",
            "[1,  4500] loss: 22.301\n",
            "[1,  4600] loss: 22.246\n",
            "[1,  4700] loss: 22.233\n",
            "[1,  4800] loss: 22.260\n",
            "[1,  4900] loss: 22.241\n",
            "[2,   100] loss: 24.397\n",
            "[2,   200] loss: 24.208\n",
            "[2,   300] loss: 23.839\n",
            "[2,   400] loss: 25.228\n",
            "[2,   500] loss: 24.879\n",
            "[2,   600] loss: 23.841\n",
            "[2,   700] loss: 23.395\n",
            "[2,   800] loss: 22.922\n",
            "[2,   900] loss: 22.774\n",
            "[2,  1000] loss: 22.319\n",
            "[2,  1100] loss: 21.712\n",
            "[2,  1200] loss: 21.851\n",
            "[2,  1300] loss: 22.061\n",
            "[2,  1400] loss: 21.748\n",
            "[2,  1500] loss: 21.552\n",
            "[2,  1600] loss: 21.490\n",
            "[2,  1700] loss: 21.393\n",
            "[2,  1800] loss: 21.465\n",
            "[2,  1900] loss: 21.747\n",
            "[2,  2000] loss: 22.023\n",
            "[2,  2100] loss: 21.935\n",
            "[2,  2200] loss: 22.084\n",
            "[2,  2300] loss: 21.971\n",
            "[2,  2400] loss: 21.853\n",
            "[2,  2500] loss: 21.821\n",
            "[2,  2600] loss: 21.664\n",
            "[2,  2700] loss: 21.621\n",
            "[2,  2800] loss: 21.781\n",
            "[2,  2900] loss: 21.876\n",
            "[2,  3000] loss: 21.929\n",
            "[2,  3100] loss: 21.779\n",
            "[2,  3200] loss: 21.876\n",
            "[2,  3300] loss: 21.770\n",
            "[2,  3400] loss: 22.017\n",
            "[2,  3500] loss: 21.927\n",
            "[2,  3600] loss: 21.998\n",
            "[2,  3700] loss: 22.125\n",
            "[2,  3800] loss: 22.057\n",
            "[2,  3900] loss: 21.985\n",
            "[2,  4000] loss: 21.943\n",
            "[2,  4100] loss: 21.877\n",
            "[2,  4200] loss: 21.859\n",
            "[2,  4300] loss: 21.940\n",
            "[2,  4400] loss: 22.014\n",
            "[2,  4500] loss: 22.104\n",
            "[2,  4600] loss: 22.114\n",
            "[2,  4700] loss: 22.089\n",
            "[2,  4800] loss: 22.125\n",
            "[2,  4900] loss: 22.182\n",
            "[3,   100] loss: 17.768\n",
            "[3,   200] loss: 23.068\n",
            "[3,   300] loss: 21.507\n",
            "[3,   400] loss: 22.227\n",
            "[3,   500] loss: 22.278\n",
            "[3,   600] loss: 22.022\n",
            "[3,   700] loss: 22.062\n",
            "[3,   800] loss: 22.688\n",
            "[3,   900] loss: 23.059\n",
            "[3,  1000] loss: 23.028\n",
            "[3,  1100] loss: 22.824\n",
            "[3,  1200] loss: 23.078\n",
            "[3,  1300] loss: 23.351\n",
            "[3,  1400] loss: 23.240\n",
            "[3,  1500] loss: 22.965\n",
            "[3,  1600] loss: 22.913\n",
            "[3,  1700] loss: 22.943\n",
            "[3,  1800] loss: 22.879\n",
            "[3,  1900] loss: 23.023\n",
            "[3,  2000] loss: 22.997\n",
            "[3,  2100] loss: 22.790\n",
            "[3,  2200] loss: 22.752\n",
            "[3,  2300] loss: 22.837\n",
            "[3,  2400] loss: 22.998\n",
            "[3,  2500] loss: 22.840\n",
            "[3,  2600] loss: 22.851\n",
            "[3,  2700] loss: 22.746\n",
            "[3,  2800] loss: 22.726\n",
            "[3,  2900] loss: 22.578\n",
            "[3,  3000] loss: 22.422\n",
            "[3,  3100] loss: 22.362\n",
            "[3,  3200] loss: 22.311\n",
            "[3,  3300] loss: 22.357\n",
            "[3,  3400] loss: 22.342\n",
            "[3,  3500] loss: 22.326\n",
            "[3,  3600] loss: 22.436\n",
            "[3,  3700] loss: 22.504\n",
            "[3,  3800] loss: 22.378\n",
            "[3,  3900] loss: 22.305\n",
            "[3,  4000] loss: 22.339\n",
            "[3,  4100] loss: 22.284\n",
            "[3,  4200] loss: 22.273\n",
            "[3,  4300] loss: 22.154\n",
            "[3,  4400] loss: 22.081\n",
            "[3,  4500] loss: 22.078\n",
            "[3,  4600] loss: 22.004\n",
            "[3,  4700] loss: 22.066\n",
            "[3,  4800] loss: 22.148\n",
            "[3,  4900] loss: 22.154\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_5NMQgkhGbk",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN3iXaeiLQpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "74f43fd7-cfcd-4f3f-ee71-1090eee2eae1"
      },
      "source": [
        "print('U1:', net.U1.weight)\n",
        "print('U2:', net.U2.weight)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "U1: Parameter containing:\n",
            "tensor([[-1.1258, -1.1524, -0.2505,  ..., -1.6959,  0.5667,  0.7935],\n",
            "        [ 0.5988, -1.5551, -0.3414,  ...,  0.1124,  0.6407,  0.4412],\n",
            "        [-0.1022,  0.7924, -0.2897,  ...,  0.7440,  1.5210,  3.4104],\n",
            "        ...,\n",
            "        [-1.0818, -1.9676, -2.2639,  ..., -1.2672,  0.1682,  1.0386],\n",
            "        [ 0.2942,  0.5609, -0.9465,  ...,  1.7208, -1.5395, -0.3518],\n",
            "        [-0.6871, -0.4509, -2.0768,  ...,  1.6216,  2.1893, -0.4871]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "U2: tensor([[ 1.2675,  0.8782,  0.3519,  ...,  2.1509, -1.3888,  0.4152],\n",
            "        [ 0.2433, -1.2376, -0.6014,  ..., -0.4035, -2.2144, -1.4043],\n",
            "        [ 0.5111,  0.4267,  0.7767,  ..., -0.3132, -0.3373,  3.4600],\n",
            "        ...,\n",
            "        [ 0.7555, -1.0806, -0.3530,  ...,  1.3783, -0.5061,  0.0167],\n",
            "        [-1.3877,  2.0509, -1.4594,  ...,  0.2739, -0.6107,  1.2204],\n",
            "        [ 2.0062,  1.0579,  0.5614,  ..., -0.1737, -0.2559,  1.0347]],\n",
            "       device='cuda:0', grad_fn=<TransposeBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}